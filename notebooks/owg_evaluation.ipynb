{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a4198e9-d153-447c-b4a9-445f2487931d",
   "metadata": {},
   "source": [
    "# OWG Evaluation Pipeline\n",
    "Author: Vanessa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc20e83b-a447-47bf-8a9e-1100d6c65cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16625433-d789-442f-9f90-974e7a28527f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "from matplotlib.patches import FancyBboxPatch\n",
    "from pprint import pprint\n",
    "\n",
    "# helper function\n",
    "%matplotlib inline\n",
    "def display_image(path_or_array, size=(10, 10)):\n",
    "  if isinstance(path_or_array, str):\n",
    "    image = np.asarray(Image.open(open(image_path, 'rb')).convert(\"RGB\"))\n",
    "  else:\n",
    "    image = path_or_array\n",
    "  \n",
    "  plt.figure(figsize=size)\n",
    "  plt.imshow(image)\n",
    "  plt.axis('off')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6c3809-4ccb-4edc-b812-a4e928f15b98",
   "metadata": {},
   "source": [
    "## Setup Pybullet Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43bffd8-cdfd-4ae3-a1b7-a34832467ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from owg_robot.env import *\n",
    "from owg_robot.camera import Camera\n",
    "from owg_robot.objects import YcbObjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b314fa96-4e7c-4df8-b207-894d06190528",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#p.disconnect()\n",
    "\n",
    "# load camera and env\n",
    "center_x, center_y, center_z = CAM_X, CAM_Y, CAM_Z\n",
    "camera = Camera((center_x, center_y, center_z), (center_x, center_y, 0.785), 0.2, 2.0, (448, 448), 40)\n",
    "env = Environment(camera, vis=True, asset_root='./owg_robot/assets', debug=False, finger_length=0.06)\n",
    "\n",
    "# load objects\n",
    "objects = YcbObjects('./owg_robot/assets/ycb_objects',\n",
    "                    mod_orn=['ChipsCan', 'MustardBottle', 'TomatoSoupCan'],\n",
    "                    mod_stiffness=['Strawberry'],\n",
    "                    seed=42\n",
    ")\n",
    "objects.shuffle_objects()\n",
    "\n",
    "n_objects = 12\n",
    "\n",
    "for obj_name in objects.obj_names[:n_objects]:\n",
    "    path, mod_orn, mod_stiffness = objects.get_obj_info(obj_name)\n",
    "    env.load_isolated_obj(path, obj_name, mod_orn, mod_stiffness)\n",
    "env.dummy_simulation_steps(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5f3815-22fb-4c0b-b5c9-20ac424a5d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from third_party.grconvnet import *\n",
    "from owg.utils.grasp import Grasp2D\n",
    "import sys\n",
    "sys.path.append('/home/owner/OWG/third_party/grconvnet')\n",
    "\n",
    "grasp_generator = load_grasp_generator(camera)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55087345-692e-41a9-888b-15e5a974f301",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_grasps(env, grasp_generator, visualise_grasps=False):\n",
    "        rgb, depth, seg = env.camera.get_cam_img()    \n",
    "        img_size = grasp_generator.IMG_WIDTH\n",
    "        if  img_size != camera.width: \n",
    "            rgb = cv2.resize(rgb, (img_size, img_size))\n",
    "            depth = cv2.resize(depth, (img_size, img_size))\n",
    "        for obj_id in env.obj_ids:\n",
    "            mask = seg == obj_id\n",
    "            if img_size != camera.width:\n",
    "                mask = np.array(Image.fromarray(mask).resize((img_size, img_size), Image.LANCZOS))\n",
    "            grasps, grasp_rects = grasp_generator.predict_grasp_from_mask(rgb,\n",
    "                                                           depth,\n",
    "                                                           mask,\n",
    "                                                           n_grasps=5, \n",
    "                                                           show_output=True\n",
    "            )\n",
    "            if img_size != camera.width:\n",
    "                # normalize to original size\n",
    "                for j, gr in enumerate(grasp_rects):\n",
    "                    grasp_rects[j][0] = int(gr[0] / img_size * camera.width)\n",
    "                    grasp_rects[j][1] = int(gr[1] / img_size * camera.width)\n",
    "                    grasp_rects[j][4] = int(gr[4] / img_size * camera.width)\n",
    "                    grasp_rects[j][3] = int(gr[3] / img_size * camera.width)\n",
    "            grasp_rects = [Grasp2D.from_vector(\n",
    "                x=g[1], y=g[0], w=g[4], h=g[3], theta=g[2], W=camera.width, H=camera.width, normalized=False, line_offset=5,\n",
    "            ) for g in grasp_rects]\n",
    "            env.set_obj_grasps(obj_id, grasps, grasp_rects)\n",
    "        \n",
    "        if visualise_grasps:\n",
    "            LID =[]\n",
    "            for obj_id in env.obj_ids:\n",
    "                grasps = env.get_obj_grasps(obj_id)\n",
    "                color = np.random.rand(3).tolist()\n",
    "                for g in grasps:\n",
    "                    LID = env.draw_predicted_grasp(g,color=color,lineIDs=LID)\n",
    "            \n",
    "            time.sleep(1)\n",
    "            env.remove_drawing(LID)\n",
    "            env.dummy_simulation_steps(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e100c4-2eaa-45a7-8b90-d80fae395152",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# run and visualize grasps -- check in your Pybullet client\n",
    "setup_grasps(env, grasp_generator, visualise_grasps=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d924ef-1a3a-4126-b65c-a4a6559c09b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = env.get_obs()\n",
    "\n",
    "all_grasp_rects = {k: env.get_obj_grasp_rects(k) for k in env.obj_ids }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7317bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Helper function for dev to reload modules\n",
    "# import  importlib\n",
    "# import owg.visual_prompt\n",
    "# importlib.reload(owg.visual_prompt)\n",
    "# from owg.visual_prompt import VisualPrompterGrounding, VisualPrompterPlanning, VisualPrompterGraspRanking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d74e9d-8420-43fc-a9fb-c2fd61bb498c",
   "metadata": {},
   "source": [
    "## Referring Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3403a72-2a9a-42fd-bb53-0ffd3633e7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "\n",
    "# openai_api_key = getpass()\n",
    "# os.environ['OPENAI_API_KEY'] = openai_api_key\n",
    "openai_api_key = \"test\"\n",
    "os.environ['OPENAI_API_KEY'] = openai_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1b071c-eb80-4d89-8bcd-1b249f1a11d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from owg.visual_prompt import VisualPrompterGrounding, VisualPrompterPlanning, VisualPrompterGraspRanking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc85bad9-9f35-480d-bc07-09f723436b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = 'config/pyb/OWG_mod.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b556dc-1467-4e46-b238-46425d7558a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "grounder = VisualPrompterGrounding(config_path, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8b37b8-76d8-4e19-9eb2-bd48136140b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "image, seg = obs['image'], obs['seg']\n",
    "obj_ids = np.unique(seg)[1:]\n",
    "all_masks = np.stack([seg == objID for objID in obj_ids])\n",
    "marker_data = {'masks': all_masks, 'labels': obj_ids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a085f7ee-0bc7-4040-b864-dc73e84d3966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show visual prompt\n",
    "visual_promppt, _ = grounder.prepare_image_prompt(image.copy(), marker_data)\n",
    "marked_image_grounding = visual_promppt[-1]\n",
    "display_image(marked_image_grounding, (6,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9294b9c1-ee43-401d-89cf-b68c40f40558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VLM request\n",
    "# user_query = \"I want to cut some paper\"\n",
    "user_query = \"I want to remove some nails\"\n",
    "# user_query = \"I want to play tennis\"\n",
    "\n",
    "dets, target_mask, target_ids, metadata_ground = grounder.request(text_query=user_query,image=image.copy(),data=marker_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399f1372-c05c-4dc2-bfe7-dfda7b192944",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_id = target_ids[0] # assume single correct object\n",
    "print(target_id)\n",
    "display_image(target_mask, (6,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d91dd4d-9b03-4e03-9cd8-d35837f7726c",
   "metadata": {},
   "source": [
    "## Grasp Planning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88464087-309a-4f91-80e9-79f0626b860a",
   "metadata": {},
   "outputs": [],
   "source": [
    "planner = VisualPrompterPlanning(config_path, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e2c69a-6431-4c3a-a636-7743de52db90",
   "metadata": {},
   "outputs": [],
   "source": [
    "plan, metadata_plan = planner.request(text_query=target_id,\n",
    "                                    image=image.copy(),\n",
    "                                    data=marker_data)\n",
    "# action = plan[0]\n",
    "action = plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4790a3-27b0-480e-ad76-b3c06c5d5c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d746a8b-c2d0-47ed-a9b7-e30af82833a7",
   "metadata": {},
   "source": [
    "## Grasp Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abe74b6-b185-41d7-9045-548f3c37c42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "grasp_ranker = VisualPrompterGraspRanking(config_path, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bacac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(seg)  # Visualize segmentation\n",
    "plt.show()\n",
    "print(\"Unique segmentation values:\", np.unique(seg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b431ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Extracted obj_ids from seg:\", obj_ids)\n",
    "print(\"Expected obj_ids from env:\", env.obj_ids)\n",
    "print(\"Number of extracted obj_ids:\", len(obj_ids))\n",
    "\n",
    "print(\"Unique object IDs in segmentation:\", np.unique(seg))\n",
    "print(\"Expected object IDs from env:\", env.obj_ids)\n",
    "\n",
    "all_masks.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859ef5be",
   "metadata": {},
   "source": [
    "### Iterable Ranking for Multiple Actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7651a03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from owg_mod.tracker import GraspStatsTracker\n",
    "# from owg_mod.mlflow_logger import MLflowLogger\n",
    "\n",
    "tracker = GraspStatsTracker()\n",
    "\n",
    "# mlogger = MLflowLogger(experiment_name=\"OWG_LLM_Tracing\")\n",
    "# mlogger.start_run(run_name=\"grasp_experiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96c89c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_and_track_actions(actions, env, image, all_masks, all_grasp_rects, obj_ids, grasp_ranker, tracker):\n",
    "    if isinstance(actions, dict):\n",
    "        actions = [actions]\n",
    "\n",
    "    for act in actions:\n",
    "        obj_id = act['input']\n",
    "        obj_grasps = all_grasp_rects[obj_id]\n",
    "        obj_mask = all_masks[np.where(obj_ids == obj_id)[0][0]]\n",
    "        req_data = {'grasps': obj_grasps, 'mask': obj_mask}\n",
    "\n",
    "        # Optional: show visual prompt\n",
    "        visual_prompt, _ = grasp_ranker.prepare_image_prompt(image.copy(), req_data)\n",
    "        marked_image_grasping = visual_prompt[-1]\n",
    "        display_image(marked_image_grasping, (12, 6))\n",
    "\n",
    "        # Rank grasps\n",
    "        sorted_grasps, best_grasp, sorted_grasp_indices, metadata_rank = grasp_ranker.request(image.copy(), req_data)\n",
    "        act['grasps'] = sorted_grasp_indices\n",
    "\n",
    "        # Execute grasp\n",
    "        if act['action'] == 'remove':\n",
    "            success_grasp, success_target, num_attempts = env.put_obj_in_free_space(obj_id, grasp_indices=act['grasps'])\n",
    "        elif act['action'] == 'pick':\n",
    "            success_grasp, success_target, num_attempts = env.put_obj_in_tray(obj_id, grasp_indices=act['grasps'])\n",
    "        else:\n",
    "            print(f\"Unknown action type: {act['action']}\")\n",
    "            continue\n",
    "\n",
    "        for _ in range(30):\n",
    "            env.step_simulation()\n",
    "\n",
    "        # Log result\n",
    "        tracker.record_grasp(\n",
    "            success=success_grasp,\n",
    "            object_id=obj_id,\n",
    "            position=env.get_obj_pos(obj_id),\n",
    "            retries=num_attempts - 1,\n",
    "            grasp_index=act['grasps'],\n",
    "            additional_info={\"timestamp\": datetime.now().isoformat()}\n",
    "        )\n",
    "        # mlogger.log_metrics({\n",
    "        #     \"success\": float(success_grasp),\n",
    "        #     \"cumulative_success_rate\": tracker.get_success_rate(),\n",
    "        # }, step=tracker.total_grasps)\n",
    "\n",
    "        tracker.set_metadata(metadata_rank, module_name=\"ranker\")\n",
    "        # mlogger.log_metrics({\n",
    "        #     \"ranker_entropy\": metadata_rank.get(\"entropy\", -1),\n",
    "        #     \"ranker_confidence\": metadata_rank.get(\"confidence\", -1),\n",
    "        # })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfcd817",
   "metadata": {},
   "outputs": [],
   "source": [
    "execute_and_track_actions(\n",
    "    actions=action,  # single dict or list of dicts\n",
    "    env=env,\n",
    "    image=image,\n",
    "    all_masks=all_masks,\n",
    "    all_grasp_rects=all_grasp_rects,\n",
    "    obj_ids=obj_ids,\n",
    "    grasp_ranker=grasp_ranker,\n",
    "    tracker=tracker\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298693c5",
   "metadata": {},
   "source": [
    "## Experiment Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e43841a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for dev to reload modules\n",
    "# import importlib\n",
    "# import owg_mod.tracker\n",
    "# importlib.reload(owg_mod.tracker)\n",
    "\n",
    "# from owg_mod.tracker import GraspStatsTracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632598aa-75d7-448a-b4dc-4669a9aa4aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set metadata (if your class expects a single dict, combine them first)\n",
    "# tracker.set_metadata({\n",
    "#     \"grounding\": metadata_ground,\n",
    "#     \"planning\": metadata_plan,\n",
    "# })\n",
    "\n",
    "tracker.set_metadata(metadata_ground, module_name=\"grounder\")\n",
    "# Log LLM uncertainty to MLflow\n",
    "# mlogger.log_metrics({\n",
    "#     \"grounder_entropy\": metadata_ground.get(\"entropy\", -1),\n",
    "#     \"grounder_confidence\": metadata_ground.get(\"confidence\", -1),\n",
    "# })\n",
    "\n",
    "tracker.set_metadata(metadata_plan, module_name=\"planner\")\n",
    "# mlogger.log_metrics({\n",
    "#     \"planner_entropy\": metadata_plan.get(\"entropy\", -1),\n",
    "#     \"planner_confidence\": metadata_plan.get(\"confidence\", -1),\n",
    "# })\n",
    "\n",
    "# Set model settings and variants\n",
    "tracker.set_model_settings({\n",
    "    \"grounder\": grounder.get_model_params(),\n",
    "    \"ranker\": grasp_ranker.get_model_params(),\n",
    "    \"planner\": planner.get_model_params()\n",
    "})\n",
    "\n",
    "tracker.set_prompt_variants({\n",
    "    \"grounder\": grounder.get_variants(),\n",
    "    \"ranker\": grasp_ranker.get_variants(),\n",
    "    \"planner\": planner.get_variants()\n",
    "})\n",
    "\n",
    "# (Optional) Tag with date, model type, or prompt variant\n",
    "# mlogger.log_params({\n",
    "#     \"grounder_model\": grounder.model_name,\n",
    "#     \"ranker_model\": grasp_ranker.model_name,\n",
    "#     \"planner_model\": planner.model_name,\n",
    "#     \"prompt_variants\": tracker.get_prompt_variants()\n",
    "# })\n",
    "\n",
    "# Print report\n",
    "print(\"Overall success rate:\", tracker.get_success_rate())\n",
    "print(\"Grasp log:\", tracker.get_log())\n",
    "summary = tracker.get_summary()\n",
    "print(\"Experiment summary:\", summary)\n",
    "tracker.save_uncertainty_log(summary)\n",
    "print(\"âœ… Uncertainty log saved to logs/uncertainty_logs.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d4a6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker.get_success_rate_per_object()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d86fe5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a6b216-00b7-4ea6-aeb1-602a24e457c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# p.disconnect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd886349",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd801ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from owg_mod.experiment_viz import ExperimentVisualizer\n",
    "\n",
    "# visualizer = ExperimentVisualizer(tracker)\n",
    "# visualizer.generate_full_report(output_dir=\"experiment_results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76862319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Helper function for dev to reload modules\n",
    "# import importlib\n",
    "# import owg_mod.experiment_visualizer\n",
    "# importlib.reload(owg_mod.experiment_visualizer)\n",
    "# from owg_mod.experiment_visualizer import ExperimentVisualizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3d1740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save metadata + logs to MLflow\n",
    "# summary_dict = tracker.get_summary()\n",
    "# mlogger.log_dict(summary_dict, artifact_file=\"experiment_summary.json\")\n",
    "\n",
    "# # Save plots as artifacts\n",
    "# import glob\n",
    "# for fig_path in glob.glob(\"experiment_results/*.png\"):\n",
    "#     mlogger.log_artifact(fig_path, artifact_path=\"plots\")\n",
    "\n",
    "# # Close MLflow run\n",
    "# mlogger.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f854c24d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
